{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Corey Book - Lightweight Character Generation\n",
    "\n",
    "**Memory-optimized version** that won't crash Colab's free tier.\n",
    "\n",
    "Uses Stable Diffusion 1.5 + ControlNet (much smaller than SDXL) with your reference images.\n",
    "\n",
    "**Features:**\n",
    "- Uses your character reference images\n",
    "- Lightweight models (fits in Colab free tier)\n",
    "- Character consistency through ControlNet\n",
    "- **Cost: FREE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Lightweight Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": "# Fix version conflicts by installing compatible versions\nprint(\"üì¶ Installing compatible packages...\")\n\n# First, upgrade huggingface_hub to fix the compatibility issue\n!pip install -q --upgrade huggingface_hub\n\n# Install compatible versions together\n!pip install -q diffusers==0.25.0 transformers==4.36.0 accelerate==0.25.0\n!pip install -q controlnet-aux opencv-python pillow\n\nprint(\"‚úÖ Compatible installation complete!\")\nprint(\"üîÑ Please restart runtime and run this cell again to avoid conflicts\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from controlnet_aux import CannyDetector\n",
    "\n",
    "# Check available memory\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"üîã GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "    \n",
    "    # Clear any existing GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected - using CPU (very slow)\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## 2. Upload Files\n",
    "\n",
    "Upload your reference images and page prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dirs"
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "os.makedirs('cartoon-characters', exist_ok=True)\n",
    "os.makedirs('page-prompts', exist_ok=True)\n",
    "os.makedirs('generated_images', exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Upload these files using the file browser (left panel):\")\n",
    "print(\"   1. cartoon-characters/corey1.jpg\")\n",
    "print(\"   2. page-prompts/page-00-cover.md through page-03.md\")\n",
    "print(\"\\nüí° Tip: You can drag and drop files directly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_files"
   },
   "outputs": [],
   "source": [
    "# Check files\n",
    "required = [\n",
    "    'cartoon-characters/corey1.jpg',\n",
    "    'page-prompts/page-00-cover.md'\n",
    "]\n",
    "\n",
    "all_good = True\n",
    "for file in required:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"‚úÖ {file}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file} - please upload\")\n",
    "        all_good = False\n",
    "\n",
    "# Show all page files found\n",
    "page_files = sorted([f for f in os.listdir('page-prompts/') if f.endswith('.md')])\n",
    "print(f\"\\nüìÑ Found {len(page_files)} page files: {page_files}\")\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\nüéâ Ready to generate!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Upload missing files before continuing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_models"
   },
   "source": [
    "## 3. Load Lightweight Models\n",
    "\n",
    "Using SD 1.5 instead of SDXL to save memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_models"
   },
   "outputs": [],
   "source": [
    "print(\"üì¶ Loading lightweight models...\")\n",
    "\n",
    "# Load ControlNet (Canny for edge detection)\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"lllyasviel/sd-controlnet-canny\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ")\n",
    "\n",
    "# Load SD 1.5 pipeline (much smaller than SDXL)\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    safety_checker=None,  # Save memory\n",
    "    requires_safety_checker=False\n",
    ")\n",
    "\n",
    "# Memory optimizations\n",
    "if device == \"cuda\":\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "    pipe.enable_attention_slicing()  # Reduce memory usage\n",
    "    pipe.enable_model_cpu_offload()  # Move models to CPU when not needed\n",
    "\n",
    "# Load Canny detector\n",
    "canny_detector = CannyDetector()\n",
    "\n",
    "print(\"‚úÖ Lightweight models loaded!\")\n",
    "print(f\"üß† Memory usage reduced - should fit in Colab free tier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "functions"
   },
   "source": [
    "## 4. Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helper_functions"
   },
   "outputs": [],
   "source": [
    "def load_page_prompt(file_path):\n",
    "    \"\"\"Load page prompt from markdown file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    title = lines[0].replace('# ', '') if lines else \"Unknown Page\"\n",
    "    \n",
    "    # Extract image prompt\n",
    "    image_prompt = \"\"\n",
    "    in_image_prompt = False\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith(\"## IMAGE PROMPT\"):\n",
    "            in_image_prompt = True\n",
    "            continue\n",
    "        elif line.startswith(\"## \"):\n",
    "            in_image_prompt = False\n",
    "            continue\n",
    "        \n",
    "        if in_image_prompt and line.strip():\n",
    "            image_prompt += line.strip() + \" \"\n",
    "    \n",
    "    return {\n",
    "        'title': title.strip(),\n",
    "        'image_prompt': image_prompt.strip()\n",
    "    }\n",
    "\n",
    "def create_prompt(page_data):\n",
    "    \"\"\"Create optimized prompt.\"\"\"\n",
    "    prompt = \"children's book illustration, cartoon style, \"\n",
    "    prompt += \"Corey: completely bald chef, no hair, round friendly face, navy blue apron, \"\n",
    "    prompt += page_data['image_prompt']\n",
    "    prompt += \" vibrant colors, cel shading, professional illustration, high quality\"\n",
    "    return prompt\n",
    "\n",
    "def prepare_control_image(ref_path, target_size=(512, 512)):\n",
    "    \"\"\"Prepare reference image for ControlNet.\"\"\"\n",
    "    if not os.path.exists(ref_path):\n",
    "        print(f\"‚ùå Reference not found: {ref_path}\")\n",
    "        return None, None\n",
    "        \n",
    "    # Load and resize reference\n",
    "    ref_image = Image.open(ref_path).convert('RGB')\n",
    "    ref_image = ref_image.resize(target_size)\n",
    "    \n",
    "    # Generate Canny edges\n",
    "    canny_image = canny_detector(ref_image)\n",
    "    \n",
    "    return ref_image, canny_image\n",
    "\n",
    "print(\"üõ†Ô∏è Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generation"
   },
   "outputs": [],
   "source": [
    "def generate_image(page_data, reference_path=\"cartoon-characters/corey1.jpg\"):\n",
    "    \"\"\"Generate image with character consistency.\"\"\"\n",
    "    \n",
    "    print(f\"üé® Generating: {page_data['title']}\")\n",
    "    \n",
    "    # Prepare control image\n",
    "    ref_image, canny_image = prepare_control_image(reference_path)\n",
    "    if ref_image is None:\n",
    "        return None\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = create_prompt(page_data)\n",
    "    negative_prompt = \"low quality, blurry, deformed, extra limbs, bad anatomy, text, watermark\"\n",
    "    \n",
    "    print(f\"üìù Prompt: {prompt[:80]}...\")\n",
    "    \n",
    "    # Clear memory before generation\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    try:\n",
    "        # Generate with ControlNet\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=canny_image,\n",
    "            controlnet_conditioning_scale=0.8,\n",
    "            num_inference_steps=20,  # Fewer steps to save time/memory\n",
    "            guidance_scale=7.5,\n",
    "            width=512,  # Smaller size for memory\n",
    "            height=512,\n",
    "            generator=torch.manual_seed(42)  # Consistent seed\n",
    "        )\n",
    "        \n",
    "        generated_image = result.images[0]\n",
    "        \n",
    "        # Upscale to 1024x1024 for final output\n",
    "        generated_image = generated_image.resize((1024, 1024), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        return generated_image, ref_image, canny_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Generation failed: {e}\")\n",
    "        # Clear memory on error\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        return None\n",
    "\n",
    "print(\"üöÄ Generation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## 5. Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_generation"
   },
   "outputs": [],
   "source": [
    "# Test with cover page\n",
    "if os.path.exists('page-prompts/page-00-cover.md'):\n",
    "    print(\"üß™ Testing with cover page...\")\n",
    "    \n",
    "    page_data = load_page_prompt('page-prompts/page-00-cover.md')\n",
    "    result = generate_image(page_data)\n",
    "    \n",
    "    if result:\n",
    "        generated, reference, canny = result\n",
    "        \n",
    "        # Show results\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        \n",
    "        axes[0].imshow(reference)\n",
    "        axes[0].set_title(\"Reference\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(canny, cmap='gray')\n",
    "        axes[1].set_title(\"Control (Canny)\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(generated)\n",
    "        axes[2].set_title(\"Generated\")\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save test result\n",
    "        generated.save('generated_images/test-cover.png')\n",
    "        print(\"üíæ Test saved as: generated_images/test-cover.png\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Test failed\")\n",
    "else:\n",
    "    print(\"‚ùå No cover page found - upload page-prompts/page-00-cover.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch"
   },
   "source": [
    "## 6. Generate All Available Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_generation"
   },
   "outputs": [],
   "source": [
    "# Find all page files\n",
    "page_files = sorted([f for f in os.listdir('page-prompts/') if f.endswith('.md')])\n",
    "\n",
    "if not page_files:\n",
    "    print(\"‚ùå No page files found. Upload some .md files to page-prompts/\")\n",
    "else:\n",
    "    print(f\"üé® Generating {len(page_files)} pages...\")\n",
    "    print(f\"üí∞ Cost: FREE (Colab GPU)\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, page_file in enumerate(page_files, 1):\n",
    "        print(f\"\\nüñºÔ∏è [{i}/{len(page_files)}] Processing {page_file}...\")\n",
    "        \n",
    "        try:\n",
    "            # Load page\n",
    "            page_data = load_page_prompt(f'page-prompts/{page_file}')\n",
    "            \n",
    "            # Generate\n",
    "            result = generate_image(page_data)\n",
    "            \n",
    "            if result:\n",
    "                generated, _, _ = result\n",
    "                \n",
    "                # Save\n",
    "                output_name = page_file.replace('.md', '.png')\n",
    "                output_path = f'generated_images/{output_name}'\n",
    "                generated.save(output_path)\n",
    "                \n",
    "                results.append(output_path)\n",
    "                print(f\"‚úÖ Saved: {output_path}\")\n",
    "                \n",
    "                # Show result\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated)\n",
    "                plt.title(page_data['title'])\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå Failed: {page_file}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with {page_file}: {e}\")\n",
    "            # Clear memory and continue\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ Complete! Generated {len(results)} images\")\n",
    "    print(f\"üìÅ Check the generated_images/ folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip_download"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# Create zip with all images\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_name = f\"corey_book_lightweight_{timestamp}.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_name, 'w') as zipf:\n",
    "    for file in os.listdir('generated_images/'):\n",
    "        if file.endswith('.png'):\n",
    "            zipf.write(f'generated_images/{file}', file)\n",
    "\n",
    "print(f\"üì¶ Created: {zip_name}\")\n",
    "print(f\"üíæ Right-click in file browser to download\")\n",
    "\n",
    "# Show what was generated\n",
    "image_files = [f for f in os.listdir('generated_images/') if f.endswith('.png')]\n",
    "print(f\"\\nüìä Generated {len(image_files)} images:\")\n",
    "for img in sorted(image_files):\n",
    "    size_mb = os.path.getsize(f'generated_images/{img}') / (1024*1024)\n",
    "    print(f\"  {img}: {size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "## Memory-Saving Tips\n",
    "\n",
    "**This lightweight version:**\n",
    "- ‚úÖ Uses SD 1.5 (smaller than SDXL)\n",
    "- ‚úÖ Generates at 512x512, upscales to 1024x1024\n",
    "- ‚úÖ Enables attention slicing & CPU offloading\n",
    "- ‚úÖ Clears GPU memory between generations\n",
    "- ‚úÖ Should work on Colab free tier\n",
    "\n",
    "**Character Consistency:**\n",
    "- Uses your `corey1.jpg` as structural reference\n",
    "- ControlNet ensures similar poses/proportions\n",
    "- Much better than text-only approaches\n",
    "\n",
    "**If it still crashes:**\n",
    "- Try generating 1-2 images at a time\n",
    "- Restart runtime between batches\n",
    "- Use Colab Pro for more RAM ($9.99/month)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}